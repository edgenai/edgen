[package]
name = "edgen_rt_llama_cpp"
version = "0.1.0"
edition = "2021"

[dependencies]
async-trait = { workspace = true }
blake3 = { workspace = true }
dashmap = { workspace = true }
derive_more = { workspace = true }
edgen_core = { path = "../edgen_core" }
futures = { workspace = true }
llama_cpp = { git = "https://github.com/edgenai/llama_cpp-rs", branch = "fix/cuda-compilation", features = ["native", "sys_verbosity"] }
thiserror = { workspace = true }
tokio = { workspace = true, features = ["sync", "rt", "fs"] }
tracing = { workspace = true }

[features]
vulkan = ["llama_cpp/vulkan"]
cuda = ["llama_cpp/cuda"]
metal = ["llama_cpp/metal"]
