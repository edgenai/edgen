export const metadata = {
  title: 'Chat',
  description: 'Generate chat completions',
}

# Chat

Generate text from text. {{ className: 'lead' }}

---

## Create chat completion {{ tag: 'POST', label: 'http://localhost:33322/v1/chat/completions' }}

<Row>
  <Col>
    Given a list of messages belonging to a chat history, generate a response.

    ### Required attributes

    <Properties>
      <Property name="messages" type="array">
        A list of messages representing a chat history. It is essentially the context used by the model to generate a response.
      </Property>
    </Properties>

    <Properties>
      <Property name="model" type="string">
        The model used for chat completions. **WARNING**: currently, this attribute is **ignored** and the **default model is used**.
      </Property>
    </Properties>

  </Col>
  <Col sticky>

    <CodeGroup title="Request" tag="POST" label="/v1/chat/completions">

    ```bash {{ title: 'cURL' }}
    curl http://localhost:33322/v1/chat/completions \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer no-key-required" \
    -d '{
      "model": "default",
      "messages": [
        {
          "role": "system",
          "content": "You are EdgenChat, a helpful AI assistant."
        },
        {
          "role": "user",
          "content": "Hello!"
        }
      ],
      "stream": true
    }'
    ```

    ```python
    from edgen import Edgen
    client = Edgen()

    completion = client.chat.completions.create(
      model="default",
      messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello!"}
      ],
      stream=True
    )

    for chunk in completion:
      print(chunk.choices[0].delta)
    ```

    ```ts
    import Edgen from "edgen";

    const client = new Edgen();

    async function main() {
      const completion = await client.chat.completions.create({
        model: "default",
        messages: [
          {"role": "system", "content": "You are a helpful assistant."},
          {"role": "user", "content": "Hello!"}
        ],
        stream: true,
      });

      for await (const chunk of completion) {
        console.log(chunk.choices[0].delta.content);
      }
    }

    main();
    ```

    </CodeGroup>

    ```json {{ title: 'Response' }}
    {"id":"e55b11e3-985b-4fbf-ba2e-5e81e6c100c2","choices":[{"delta":{"content":"Hello","role":null},"finish_reason":null,"index":0}],"created":1706718034,"model":"main","system_fingerprint":"edgen-0.1.0","object":"text_completion"}

    {"id":"010b3954-af7c-4360-9891-1d6c5e27da8c","choices":[{"delta":{"content":"!","role":null},"finish_reason":null,"index":0}],"created":1706718040,"model":"main","system_fingerprint":"edgen-0.1.0","object":"text_completion"}

    {"id":"7455343f-99bc-4d63-9d03-cc8e75fab29c","choices":[{"delta":{"content":" How","role":null},"finish_reason":null,"index":0}],"created":1706718044,"model":"main","system_fingerprint":"edgen-0.1.0","object":"text_completion"}

    {"id":"82f72e44-162d-4e21-93c6-387950a61c79","choices":[{"delta":{"content":" can","role":null},"finish_reason":null,"index":0}],"created":1706718049,"model":"main","system_fingerprint":"edgen-0.1.0","object":"text_completion"}

    {"id":"7d451531-d117-48b1-9e68-2554338e34ba","choices":[{"delta":{"content":" I","role":null},"finish_reason":null,"index":0}],"created":1706718053,"model":"main","system_fingerprint":"edgen-0.1.0","object":"text_completion"}

    {"id":"66fe6034-c97d-4c46-8c05-bf73804e557d","choices":[{"delta":{"content":" assist","role":null},"finish_reason":null,"index":0}],"created":1706718059,"model":"main","system_fingerprint":"edgen-0.1.0","object":"text_completion"}

    {"id":"56a260a8-f41b-4954-9b67-e6620fb32f0d","choices":[{"delta":{"content":" you","role":null},"finish_reason":null,"index":0}],"created":1706718063,"model":"main","system_fingerprint":"edgen-0.1.0","object":"text_completion"}

    {"id":"ccef46ce-ba8b-4ac8-8262-a66cb96832a5","choices":[{"delta":{"content":" today","role":null},"finish_reason":null,"index":0}],"created":1706718068,"model":"main","system_fingerprint":"edgen-0.1.0","object":"text_completion"}

    {"id":"0d2b9ba2-ab04-4aed-ad51-72a89acb3122","choices":[{"delta":{"content":"?","role":null},"finish_reason":null,"index":0}],"created":1706718069,"model":"main","system_fingerprint":"edgen-0.1.0","object":"text_completion"}
    ```

  </Col>
</Row>

---

## Chat completion status {{ tag: 'GET', label: 'http://localhost:33322/v1/chat/completions/status' }}

<Row>
  <Col>
    Shows the current status of the chat completions endpoint (e.g. downloads).
  </Col>
  <Col sticky>

    <CodeGroup title="Request" tag="GET" label="/v1/chat/completions/status">

    ```bash {{ title: 'cURL' }}
    curl http://localhost:33322/v1/chat/completions/status \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer no-key-required" \
    ```

    ```python
    from edgen import Edgen
    client = Edgen()

    status = client.chat.completions.status.create()
    print(status)

    ```

    ```ts
    import Edgen from "edgen";

    const client = new Edgen();

    async function main() {
      const status = await client.chat.completions.status.create();

      console.log(status);
    }

    main();
    ```

    </CodeGroup>

    ```json {{ title: 'Response' }}
    {"active_model":"neural-chat-7b-v3-3.Q4_K_M.gguf","last_activity":"download","last_activity_result":"success","completions_ongoing":false,"download_ongoing":false,"download_progress":100,"last_errors":["Custom { kind: PermissionDenied, error: \"verboten\" }]}
    ```

  </Col>
</Row>
